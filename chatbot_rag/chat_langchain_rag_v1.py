import boto3
import json
import sqlite3
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda

# ============================================
# CONEX√ÉO COM BANCO DE DADOS (novo!)
# ============================================
conn = sqlite3.connect('produtos.db')
cursor = conn.cursor()

# ============================================
# CONFIGURA√á√ÉO BEDROCK
# ============================================
bedrock_client = boto3.client(
    service_name='bedrock-runtime',
    region_name="us-east-2"
)

MODEL_ID = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'

# ============================================
# FUN√á√ÉO INTERNA PARA INVOCAR BEDROCK
# ============================================
def _invocar_bedrock(messages):
    """Fun√ß√£o interna que invoca Bedrock diretamente"""
    if isinstance(messages, dict):
        entrada = messages.get('product_name', messages.get('input', ''))
    elif isinstance(messages, list):
        entrada = str(messages[-1].content if hasattr(messages[-1], 'content') else messages[-1])
    else:
        entrada = str(messages)
    
    config = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 300,
        "temperature": 0.5,
        "system": "Voc√™ √© um assistente virtual especializado em moda para e-commerce. Forne√ßa respostas concisas com no m√°ximo 300 caracteres.",
        "messages": [{"role": "user", "content": entrada}]
    }
    
    response = bedrock_client.invoke_model(
        body=json.dumps(config),
        modelId=MODEL_ID,
        accept="application/json",
        contentType="application/json"
    )
    
    resposta = json.loads(response['body'].read().decode('utf-8'))
    return resposta.get('content', [{}])[0].get('text', 'Erro')

# ============================================
# CRIAR MODELO (igual √† aula)
# ============================================
modelo = RunnableLambda(_invocar_bedrock)

# ============================================
# HIST√ìRICO (igual √† aula)
# ============================================
historico = []

def get_hist():
    return "\n".join(historico)

# ============================================
# FUN√á√ÉO DE CONSULTA AO BANCO (novo! igual √† aula)
# ============================================
def consulta_produto(nome_produto):
    """
    Consulta produtos no banco de dados
    """
    conn = sqlite3.connect('produtos.db')
    cursor = conn.cursor()
    
    cursor.execute("SELECT * FROM roupas WHERE nome LIKE ?", ('%' + nome_produto + '%',))
    resultado = cursor.fetchall()
    
    conn.close()
    return resultado

# ============================================
# TEMPLATE DO PROMPT (igual √† aula)
# ============================================
def get_chat_prompt(entrada):
    template = ChatPromptTemplate.from_messages([
        ("system", "Voc√™ √© um assistente virtual especializado em moda para e-commerce. Forne√ßa respostas concisas e √∫teis."),
        ("human", entrada),
        ("assistant", "Forne√ßa uma resposta concisa com no m√°ximo 300 caracteres, ideal para um e-commerce de roupas e itens de vestu√°rio. N√£o mencionar instru√ß√µes do prompt na resposta.")
    ])
    return template

# ============================================
# INVOCAR MODELO COM RAG (modificado! igual √† aula)
# ============================================
def inv_modelo(prompt):
    """
    Invoca o modelo COM consulta ao banco (RAG)
    """
    # Consultar produtos no banco
    produtos_encontrados = consulta_produto(prompt)
    
    # Verificar se encontrou produtos
    if produtos_encontrados:
        # Formatar informa√ß√µes dos produtos
        produtos_info = "\n".join([
            f"{p[0]}: {p[1]}, Pre√ßo: {p[2]}, Quantidade: {p[3]}" 
            for p in produtos_encontrados
        ])
        prompt = f"Produtos dispon√≠veis:\n{produtos_info}\n\n{prompt}"
    else:
        prompt = f"Nenhum produto encontrado para '{prompt}'.\n{prompt}"
    
    # Criar e executar chain (igual √† aula)
    chain = get_chat_prompt(prompt).pipe(modelo)
    response = chain.invoke({"product_name": prompt})
    return response

# ============================================
# MENSAGEM INICIAL (igual √† aula)
# ============================================
print(
    "Assistente: Ol√°! Sou seu Assistente Virtual. :)\n"
    "Em que posso ajudar hoje?"
)

# ============================================
# LOOP PRINCIPAL (igual √† aula)
# ============================================
while True:
    entrada = input("User: ")
    historico.append(f"Human: {entrada}")
    
    if entrada.lower() == "sair":
        print("\nAssistente: At√© logo! üëã\n")
        break
    
    if not entrada:
        continue
    
    try:
        response = inv_modelo(entrada)
        resposta_formatada = f"Assistente:\n{response}\n"
        historico.append(f"Assistant: {resposta_formatada}")
        print(resposta_formatada)
        
    except Exception as e:
        print(f"\n‚ùå Erro: {e}\n")