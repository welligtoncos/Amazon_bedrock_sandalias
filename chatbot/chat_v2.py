import boto3
import json

# ============================================
# CONFIGURA√á√ïES
# ============================================
client = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-east-2'
)

MODEL_ID = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'  # Custo 73% menor
MAX_HISTORICO = 10  # Limita hist√≥rico para controlar custos

# System Prompt (instru√ß√µes gerais do assistente)
SYSTEM_PROMPT = """Voc√™ √© um assistente virtual da Meteora, um e-commerce de moda e vestu√°rio.

DIRETRIZES:
- Seja conciso: m√°ximo 300 caracteres por resposta
- Foque em produtos de moda: roupas, cal√ßados, acess√≥rios
- Mantenha tom profissional e amig√°vel
- Use o contexto das mensagens anteriores
- N√£o mencione limita√ß√µes t√©cnicas
- Sempre ofere√ßa alternativas quando poss√≠vel"""

# ============================================
# CLASSE DO CHATBOT
# ============================================
class ChatbotMeteora:
    """
    Chatbot inteligente com hist√≥rico de conversa
    """
    
    def __init__(self):
        self.historico = []  # Lista de mensagens {role, content}
        self.max_historico = MAX_HISTORICO
    
    def adicionar_mensagem(self, role, content):
        """
        Adiciona mensagem ao hist√≥rico
        role: 'user' ou 'assistant'
        """
        self.historico.append({
            "role": role,
            "content": content
        })
        
        # Limitar hist√≥rico (mant√©m √∫ltimas N conversas)
        # Cada conversa = 1 user + 1 assistant = 2 mensagens
        if len(self.historico) > self.max_historico * 2:
            # Remove as mais antigas, mant√©m as mais recentes
            self.historico = self.historico[-self.max_historico * 2:]
    
    def limpar_historico(self):
        """Limpa todo o hist√≥rico"""
        self.historico = []
    
    def obter_resposta(self, mensagem_usuario):
        """
        Envia mensagem e obt√©m resposta do modelo
        """
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        self.adicionar_mensagem("user", mensagem_usuario)
        
        try:
            # Configurar requisi√ß√£o com hist√≥rico completo
            config = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 300,
                "temperature": 0.5,
                "system": SYSTEM_PROMPT,
                "messages": self.historico  # Envia todo o hist√≥rico
            }
            
            # Invocar modelo
            response = client.invoke_model(
                body=json.dumps(config),
                modelId=MODEL_ID,
                accept="application/json",
                contentType="application/json"
            )
            
            # Processar resposta
            resposta = json.loads(response['body'].read().decode('utf-8'))
            texto_resposta = resposta.get('content', [{}])[0].get('text', 'Erro ao processar')
            
            # Adicionar resposta do assistente ao hist√≥rico
            self.adicionar_mensagem("assistant", texto_resposta)
            
            return texto_resposta
            
        except client.exceptions.ThrottlingException:
            # Remove √∫ltima mensagem do usu√°rio se falhou
            if self.historico and self.historico[-1]["role"] == "user":
                self.historico.pop()
            return "‚ö†Ô∏è Muitas requisi√ß√µes. Aguarde um momento e tente novamente."
        
        except Exception as e:
            # Remove √∫ltima mensagem do usu√°rio se falhou
            if self.historico and self.historico[-1]["role"] == "user":
                self.historico.pop()
            return f"‚ùå Erro: {str(e)}"
    
    def iniciar(self):
        """
        Inicia o loop de conversa
        """
        print("=" * 80)
        print("üõçÔ∏è  METEORA - ASSISTENTE VIRTUAL v2")
        print("=" * 80)
        print("\nüëã Ol√°! Sou seu Assistente Virtual da Meteora.")
        print("Em que posso ajudar hoje?\n")
        print("üí° COMANDOS:")
        print("   ‚Ä¢ Digite sua pergunta normalmente")
        print("   ‚Ä¢ 'sair' ou 'tchau' ‚Üí Encerrar")
        print("   ‚Ä¢ 'limpar' ‚Üí Limpar hist√≥rico de conversa")
        print("   ‚Ä¢ 'historico' ‚Üí Ver quantas mensagens est√£o armazenadas\n")
        print("-" * 80 + "\n")
        
        while True:
            # Capturar entrada
            try:
                entrada = input("üßë Voc√™: ").strip()
            except KeyboardInterrupt:
                print("\n\nüëã At√© logo!\n")
                break
            
            # Verificar comandos especiais
            if entrada.lower() in ['sair', 'exit', 'quit', 'tchau', 'bye']:
                print("\nü§ñ Assistente: Foi um prazer ajud√°-lo(a)! Volte sempre! üëã\n")
                break
            
            if entrada.lower() == 'limpar':
                self.limpar_historico()
                print("\nüóëÔ∏è  Hist√≥rico limpo! Conversa reiniciada.\n")
                continue
            
            if entrada.lower() == 'historico':
                num_conversas = len(self.historico) // 2
                print(f"\nüìä Hist√≥rico: {num_conversas} conversas armazenadas")
                print(f"   (M√°ximo: {self.max_historico} conversas)\n")
                continue
            
            # Ignorar entradas vazias
            if not entrada:
                continue
            
            # Obter e exibir resposta
            resposta = self.obter_resposta(entrada)
            print(f"\nü§ñ Assistente: {resposta}\n")
            print("-" * 80 + "\n")

# ============================================
# EXECUTAR
# ============================================
if __name__ == "__main__":
    chatbot = ChatbotMeteora()
    chatbot.iniciar()