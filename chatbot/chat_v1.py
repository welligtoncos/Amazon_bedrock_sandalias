import boto3
import json

# Cliente Bedrock Runtime
client = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-east-2'
)

# Modelo: Claude 3.5 Haiku (custo baixo)
MODEL_ID = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'

def get_config(prompt: str):
    """
    Configura√ß√£o da requisi√ß√£o para o modelo Claude 3.5 Haiku
    Usando Messages API (formato moderno)
    """
    return json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 300,
        "temperature": 0.5,
        "system": """Voc√™ √© um assistente virtual da Meteora, um e-commerce de moda e vestu√°rio.
        Suas respostas devem ser:
        - Concisas (m√°ximo 300 caracteres)
        - Focadas em produtos de moda e vestu√°rio
        - Profissionais e amig√°veis
        - Orientadas para ajudar o cliente a encontrar produtos
        - Sem mencionar limita√ß√µes t√©cnicas""",
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    })

def processar_resposta(response):
    """
    Processa a resposta do modelo e extrai o texto
    """
    try:
        resposta = json.loads(response['body'].read().decode('utf-8'))
        texto = resposta.get('content', [{}])[0].get('text', 'Resposta n√£o encontrada')
        return texto
    except Exception as e:
        return f"Erro ao processar resposta: {e}"

def iniciar_chat():
    """
    Fun√ß√£o principal do chatbot
    """
    print("=" * 80)
    print("üõçÔ∏è  METEORA - ASSISTENTE VIRTUAL")
    print("=" * 80)
    print("\nAssistente: Ol√°! Sou seu Assistente Virtual da Meteora. üòä")
    print("Em que posso ajudar hoje?")
    print("\nüí° Dica: Digite 'sair' para encerrar\n")
    
    while True:
        # Capturar entrada do usu√°rio
        entrada = input("Voc√™: ").strip()
        
        # Verificar se quer sair
        if entrada.lower() in ['sair', 'exit', 'quit', 'tchau']:
            print("\nAssistente: Foi um prazer ajud√°-lo(a)! At√© logo! üëã\n")
            break
        
        # Ignorar entradas vazias
        if not entrada:
            continue
        
        try:
            # Enviar requisi√ß√£o ao modelo
            response = client.invoke_model(
                body=get_config(entrada),
                modelId=MODEL_ID,
                accept="application/json",
                contentType="application/json"
            )
            
            # Processar e exibir resposta
            resposta_texto = processar_resposta(response)
            print(f"\nAssistente: {resposta_texto}\n")
            
        except client.exceptions.ThrottlingException:
            print("\n‚ö†Ô∏è Muitas requisi√ß√µes. Aguarde um momento...\n")
        except Exception as e:
            print(f"\n‚ùå Erro: {e}\n")

# Executar chatbot
if __name__ == "__main__":
    iniciar_chat()